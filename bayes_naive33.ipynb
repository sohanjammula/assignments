{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c98881-edf7-47c6-ad29-adec5ec0e320",
   "metadata": {},
   "source": [
    "#### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296679bd-2a4e-4251-ae1d-2f5317168991",
   "metadata": {},
   "source": [
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use Bayes' theorem.\n",
    "\n",
    "Let's define the events:\n",
    "\n",
    "Event \n",
    "ğ´\n",
    "A: an employee uses the health insurance plan.\n",
    "Event \n",
    "ğµ\n",
    "B: an employee is a smoker.\n",
    "We are asked to find \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A), the probability that an employee is a smoker given that he/she uses the health insurance plan.\n",
    "\n",
    "Given:\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "P(A), the probability that an employee uses the health insurance plan, is 70% or 0.70.\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A), the conditional probability that an employee is a smoker given that he/she uses the health insurance plan, is 40% or 0.40.\n",
    "We can calculate \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B), the probability that an employee is a smoker, using the law of total probability. Then, we can use Bayes' theorem to calculate \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A).\n",
    "\n",
    "The law of total probability states:\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "+\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(B)=P(Bâˆ£A)â‹…P(A)+P(Bâˆ£Â¬A)â‹…P(Â¬A)\n",
    "\n",
    "Where:\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£Â¬A) is the probability that an employee is a smoker given that he/she does not use the health insurance plan. Since this information is not provided, we will assume it is independent of whether the employee uses the health insurance plan or not.\n",
    "ğ‘ƒ\n",
    "(\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(Â¬A) is the probability that an employee does not use the health insurance plan, which is \n",
    "1\n",
    "âˆ’\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "1âˆ’P(A).\n",
    "Let's calculate \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B) and then use Bayes' theorem to find \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A):\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "+\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(B)=P(Bâˆ£A)â‹…P(A)+P(Bâˆ£Â¬A)â‹…P(Â¬A)\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "(\n",
    "0.40\n",
    "â‹…\n",
    "0.70\n",
    ")\n",
    "+\n",
    "(\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "0.70\n",
    ")\n",
    ")\n",
    "P(B)=(0.40â‹…0.70)+(P(Bâˆ£Â¬A)â‹…(1âˆ’0.70))\n",
    "\n",
    "We do not have information about \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£Â¬A), so we cannot calculate \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B) directly. However, we can still use Bayes' theorem to find \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A):\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "=\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    "âˆ£\n",
    "ğµ\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A)= \n",
    "P(A)\n",
    "P(Aâˆ£B)â‹…P(B)\n",
    "â€‹\n",
    " \n",
    "\n",
    "Given that we are asked to find \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A), we already know \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    "âˆ£\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "0.40\n",
    "P(Aâˆ£B)=0.40 (given in the problem statement). We can now use Bayes' theorem to calculate \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A). Let's calculate it:\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "=\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    "âˆ£\n",
    "ğµ\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A)= \n",
    "P(A)\n",
    "P(Aâˆ£B)â‹…P(B)\n",
    "â€‹\n",
    " \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "=\n",
    "0.40\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "0.70\n",
    "P(Bâˆ£A)= \n",
    "0.70\n",
    "0.40â‹…P(B)\n",
    "â€‹\n",
    " \n",
    "\n",
    "Since we don't have the value of \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B), we cannot compute \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A) exactly without additional information. However, we can calculate \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A) relative to \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B), and then use the law of total probability to find the actual value of \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B).\n",
    "\n",
    "Let's proceed to calculate \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A) relative to \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B):\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "=\n",
    "0.40\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "0.70\n",
    "P(Bâˆ£A)= \n",
    "0.70\n",
    "0.40â‹…P(B)\n",
    "â€‹\n",
    " \n",
    "\n",
    "Now, let's solve this equation to find \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A) relative to \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B).\n",
    "\n",
    "continue\n",
    "ChatGPT\n",
    "To find \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A) relative to \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B), we first need to express \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B) in terms of \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A) using the law of total probability:\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "+\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(B)=P(Bâˆ£A)â‹…P(A)+P(Bâˆ£Â¬A)â‹…P(Â¬A)\n",
    "\n",
    "Since we don't have the value of \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£Â¬A) and \n",
    "ğ‘ƒ\n",
    "(\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(Â¬A), we cannot directly compute \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B). However, we can express \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "Â¬\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£Â¬A) as \n",
    "1\n",
    "âˆ’\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "1âˆ’P(Bâˆ£A) because the probabilities must sum up to 1.\n",
    "\n",
    "Now, let's rewrite the equation for \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B):\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "â‹…\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    "+\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    ")\n",
    "â‹…\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğ´\n",
    ")\n",
    ")\n",
    "P(B)=P(Bâˆ£A)â‹…P(A)+(1âˆ’P(Bâˆ£A))â‹…(1âˆ’P(A))\n",
    "\n",
    "Substituting the given probabilities:\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "0.40\n",
    "Ã—\n",
    "0.70\n",
    "+\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "0.40\n",
    ")\n",
    "Ã—\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "0.70\n",
    ")\n",
    "P(B)=0.40Ã—0.70+(1âˆ’0.40)Ã—(1âˆ’0.70)\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "0.28\n",
    "+\n",
    "0.6\n",
    "Ã—\n",
    "0.3\n",
    "P(B)=0.28+0.6Ã—0.3\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "0.28\n",
    "+\n",
    "0.18\n",
    "P(B)=0.28+0.18\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "=\n",
    "0.46\n",
    "P(B)=0.46\n",
    "\n",
    "Now that we have found \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B), we can use Bayes' theorem to find \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "P(Bâˆ£A) relative to \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    ")\n",
    "P(B):\n",
    "\n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "=\n",
    "0.40\n",
    "Ã—\n",
    "0.46\n",
    "0.70\n",
    "P(Bâˆ£A)= \n",
    "0.70\n",
    "0.40Ã—0.46\n",
    "â€‹\n",
    " \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "=\n",
    "0.184\n",
    "0.70\n",
    "P(Bâˆ£A)= \n",
    "0.70\n",
    "0.184\n",
    "â€‹\n",
    " \n",
    "ğ‘ƒ\n",
    "(\n",
    "ğµ\n",
    "âˆ£\n",
    "ğ´\n",
    ")\n",
    "â‰ˆ\n",
    "0.2629\n",
    "P(Bâˆ£A)â‰ˆ0.2629\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is approximately \n",
    "0.2629\n",
    "0.2629, or \n",
    "26.29\n",
    "%\n",
    "26.29%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a179d1-1c65-4328-a4db-955484701431",
   "metadata": {},
   "source": [
    "#### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15435e6-657e-4372-92e1-da2855f3c077",
   "metadata": {},
   "source": [
    "The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type of data they are designed to handle and the underlying probability distributions they assume for the features.\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Bernoulli Naive Bayes is typically used for binary or boolean feature data, where each feature represents the presence or absence of a particular attribute.\n",
    "It assumes that features are binary variables (0 or 1), and it models the presence or absence of each feature independently.\n",
    "It is commonly used in text classification tasks, where the presence or absence of words in documents is used as features.\n",
    "Bernoulli Naive Bayes computes the likelihood of each feature being present or absent in each class and combines these likelihoods using Bayes' theorem to make predictions.\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Multinomial Naive Bayes is designed for data with features that represent counts or frequencies, such as word counts in text data.\n",
    "It assumes that features follow a multinomial distribution, where each feature represents the frequency of occurrence of a particular event (e.g., word count in a document).\n",
    "It is commonly used in text classification tasks, where the frequency of words in documents is used as features.\n",
    "Multinomial Naive Bayes computes the likelihood of observing each feature value (frequency) given each class and combines these likelihoods using Bayes' theorem to make predictions.\n",
    "In summary, Bernoulli Naive Bayes is suitable for binary feature data, while Multinomial Naive Bayes is suitable for count or frequency-based feature data. They differ in the underlying probability distributions they assume for the features and are often used in different types of text classification tasks, although they can also be applied to other types of data with appropriate feature representations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e3f25-1442-46c1-9840-2cf8863181ef",
   "metadata": {},
   "source": [
    "#### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b7995-9f4f-49d6-b8cb-ee2be379983b",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes handles missing values by considering them as a separate category or state of the feature. In other words, when encountering a missing value for a feature, Bernoulli Naive Bayes treats it as an additional category alongside the existing categories (e.g., presence and absence) for binary features.\n",
    "\n",
    "Here's how Bernoulli Naive Bayes typically handles missing values:\n",
    "\n",
    "Imputation:\n",
    "\n",
    "One common approach is to impute the missing values with a placeholder value that represents the absence of the feature. For binary features, this placeholder value could be 0, indicating the absence of the feature.\n",
    "By imputing missing values with a placeholder value, the missing values are treated as if the feature is absent, which aligns with the binary nature of the features in Bernoulli Naive Bayes.\n",
    "Separate Category:\n",
    "\n",
    "Alternatively, Bernoulli Naive Bayes can treat missing values as a separate category or state of the feature.\n",
    "In this approach, a missing value is considered as a distinct category alongside the existing categories (e.g., presence and absence) for binary features.\n",
    "When calculating probabilities, the presence of a missing value is treated as a separate event with its own likelihood.\n",
    "Model Adaptation:\n",
    "\n",
    "Bernoulli Naive Bayes models can be adapted to explicitly handle missing values by modifying the probability estimation process.\n",
    "For example, the model can estimate separate probabilities for observing a missing value in each class, similar to how it estimates probabilities for observing the presence or absence of the feature.\n",
    "This adaptation allows the model to learn from the available data and make predictions even when some feature values are missing.\n",
    "Overall, Bernoulli Naive Bayes can handle missing values by treating them as a separate category or by imputing them with a placeholder value that represents the absence of the feature. The specific approach depends on the implementation and the requirements of the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cb64-a693-4871-8096-049685642ac7",
   "metadata": {},
   "source": [
    "#### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c132f7-7089-480a-98c6-3cab3fa6e410",
   "metadata": {},
   "source": [
    "Yes, Gaussian Naive Bayes can be used for multi-class classification tasks. Gaussian Naive Bayes is an extension of the Naive Bayes algorithm that assumes continuous features follow a Gaussian (normal) distribution. It is commonly used for classification tasks where the features are continuous variables.\n",
    "\n",
    "In the case of multi-class classification, where there are more than two classes to predict, Gaussian Naive Bayes can still be applied. The algorithm calculates the probability of each class given the observed feature values using Bayes' theorem and assumes that the features are conditionally independent given the class label.\n",
    "\n",
    "Here's how Gaussian Naive Bayes can be used for multi-class classification:\n",
    "\n",
    "Model Training:\n",
    "\n",
    "During training, the algorithm estimates the parameters of the Gaussian distribution (mean and variance) for each feature in each class.\n",
    "It computes the class priors based on the frequency of each class in the training data.\n",
    "Prediction:\n",
    "\n",
    "Given a new instance with feature values, Gaussian Naive Bayes calculates the likelihood of observing those feature values in each class using the Gaussian probability density function.\n",
    "It combines the likelihoods with the class priors using Bayes' theorem to compute the posterior probability of each class given the observed feature values.\n",
    "The class with the highest posterior probability is predicted as the output class for the new instance.\n",
    "Multi-class Classification:\n",
    "\n",
    "For multi-class classification, Gaussian Naive Bayes extends the binary classification approach to handle multiple classes.\n",
    "It computes the likelihoods and posterior probabilities for each class, considering all classes in the dataset.\n",
    "Gaussian Naive Bayes is particularly suitable for multi-class classification tasks where the features follow a Gaussian distribution or can be approximated as such. It is often used in various applications, including text classification, medical diagnosis, and image recognition, where the features may represent continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546b069-3c53-4900-a3c5-7bdb7088ab83",
   "metadata": {},
   "source": [
    "####Data preparation: Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/ datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "255f7ea7-4091-4f84-95b0-71f4345a42f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the spambase.data file into a DataFrame\n",
    "# Assuming the file is located in the same directory as the notebook\n",
    "# If not, provide the full path to the file\n",
    "df = pd.read_csv('spambase.data',header=None)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('spambase.csv', index=False)\n",
    "\n",
    "# Optionally, display the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3092ad-62e1-45a7-ab98-7ab9182e791e",
   "metadata": {},
   "source": [
    "#### Implementation: Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8d4a49d-7ff6-46b0-a004-5062fa4c0bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (Bernoulli Naive Bayes): 0.8839380364047911\n",
      "Mean Accuracy (Multinomial Naive Bayes): 0.7863496180326323\n",
      "Mean Accuracy (Gaussian Naive Bayes): 0.8217730830896915\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "# Load the Spambase dataset\n",
    "data = pd.read_csv('spambase.csv')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = data.drop('57', axis=1)\n",
    "y = data['57']\n",
    "\n",
    "# Initialize the classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Perform 10-fold cross-validation and evaluate the classifiers\n",
    "scores_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='accuracy')\n",
    "scores_multinomial = cross_val_score(multinomial_nb, X, y, cv=10, scoring='accuracy')\n",
    "scores_gaussian = cross_val_score(gaussian_nb, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Print the mean accuracy scores for each classifier\n",
    "print(\"Mean Accuracy (Bernoulli Naive Bayes):\", scores_bernoulli.mean())\n",
    "print(\"Mean Accuracy (Multinomial Naive Bayes):\", scores_multinomial.mean())\n",
    "print(\"Mean Accuracy (Gaussian Naive Bayes):\", scores_gaussian.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab530a35-b1c2-435c-808c-ee6e5ed891fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1     2    3     4     5    6    7    8    9  ...     48     49  \\\n",
       "4596  0.31  0.0  0.62  0.0  0.00  0.31  0.0  0.0  0.0  0.0  ...  0.000  0.232   \n",
       "4597  0.00  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...  0.000  0.000   \n",
       "4598  0.30  0.0  0.30  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...  0.102  0.718   \n",
       "4599  0.96  0.0  0.00  0.0  0.32  0.00  0.0  0.0  0.0  0.0  ...  0.000  0.057   \n",
       "4600  0.00  0.0  0.65  0.0  0.00  0.00  0.0  0.0  0.0  0.0  ...  0.000  0.000   \n",
       "\n",
       "       50     51   52   53     54  55   56  57  \n",
       "4596  0.0  0.000  0.0  0.0  1.142   3   88   0  \n",
       "4597  0.0  0.353  0.0  0.0  1.555   4   14   0  \n",
       "4598  0.0  0.000  0.0  0.0  1.404   6  118   0  \n",
       "4599  0.0  0.000  0.0  0.0  1.147   5   78   0  \n",
       "4600  0.0  0.125  0.0  0.0  1.250   5   40   0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025bafb0-0297-4210-bd26-eeae06cfde93",
   "metadata": {},
   "source": [
    "#### Report the following performance metrics for each classifier: Accuracy Precision Recall F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a663c6af-beaa-4144-9850-9eb2267c8c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for Bernoulli Naive Bayes:\n",
      "Accuracy: 0.8839382742881983\n",
      "Precision: 0.8813357185450209\n",
      "Recall: 0.815223386651958\n",
      "F1 Score: 0.8469914040114614\n",
      "\n",
      "Performance Metrics for Multinomial Naive Bayes:\n",
      "Accuracy: 0.786350793305803\n",
      "Precision: 0.7323628219484882\n",
      "Recall: 0.7214561500275786\n",
      "F1 Score: 0.7268685746040567\n",
      "\n",
      "Performance Metrics for Gaussian Naive Bayes:\n",
      "Accuracy: 0.8217778743751358\n",
      "Precision: 0.7004440855874041\n",
      "Recall: 0.9569773855488142\n",
      "F1 Score: 0.8088578088578089\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "y_pred_bernoulli = cross_val_predict(bernoulli_nb, X, y, cv=10)\n",
    "y_pred_multinomial = cross_val_predict(multinomial_nb, X, y, cv=10)\n",
    "y_pred_gaussian = cross_val_predict(gaussian_nb, X, y, cv=10)\n",
    "\n",
    "# Calculate performance metrics for each classifier\n",
    "accuracy_bernoulli = accuracy_score(y, y_pred_bernoulli)\n",
    "precision_bernoulli = precision_score(y, y_pred_bernoulli)\n",
    "recall_bernoulli = recall_score(y, y_pred_bernoulli)\n",
    "f1_bernoulli = f1_score(y, y_pred_bernoulli)\n",
    "\n",
    "accuracy_multinomial = accuracy_score(y, y_pred_multinomial)\n",
    "precision_multinomial = precision_score(y, y_pred_multinomial)\n",
    "recall_multinomial = recall_score(y, y_pred_multinomial)\n",
    "f1_multinomial = f1_score(y, y_pred_multinomial)\n",
    "\n",
    "accuracy_gaussian = accuracy_score(y, y_pred_gaussian)\n",
    "precision_gaussian = precision_score(y, y_pred_gaussian)\n",
    "recall_gaussian = recall_score(y, y_pred_gaussian)\n",
    "f1_gaussian = f1_score(y, y_pred_gaussian)\n",
    "\n",
    "# Print the performance metrics for each classifier\n",
    "print(\"Performance Metrics for Bernoulli Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_bernoulli)\n",
    "print(\"Precision:\", precision_bernoulli)\n",
    "print(\"Recall:\", recall_bernoulli)\n",
    "print(\"F1 Score:\", f1_bernoulli)\n",
    "print()\n",
    "\n",
    "print(\"Performance Metrics for Multinomial Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_multinomial)\n",
    "print(\"Precision:\", precision_multinomial)\n",
    "print(\"Recall:\", recall_multinomial)\n",
    "print(\"F1 Score:\", f1_multinomial)\n",
    "print()\n",
    "\n",
    "print(\"Performance Metrics for Gaussian Naive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_gaussian)\n",
    "print(\"Precision:\", precision_gaussian)\n",
    "print(\"Recall:\", recall_gaussian)\n",
    "print(\"F1 Score:\", f1_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d78c63-88a3-48ce-9abe-6a7f816b1280",
   "metadata": {},
   "source": [
    "#### Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e87d9b-ad81-4a35-a52d-ea03a20ea13e",
   "metadata": {},
   "source": [
    "After evaluating the performance of Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes on the Spambase dataset using 10-fold cross-validation, we can discuss the results obtained and analyze the performance of each variant of Naive Bayes.\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "Accuracy: Measures the overall correctness of the classifier's predictions.\n",
    "Precision: Measures the proportion of true positive predictions among all positive predictions made by the classifier.\n",
    "Recall: Measures the proportion of true positive predictions among all actual positive instances in the dataset.\n",
    "F1 Score: Harmonic mean of precision and recall, providing a balanced measure of classifier performance.\n",
    "Results:\n",
    "Based on the performance metrics obtained from the cross-validation experiments, we can observe the following:\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Accuracy: [Calculated Value]\n",
    "Precision: [Calculated Value]\n",
    "Recall: [Calculated Value]\n",
    "F1 Score: [Calculated Value]\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Accuracy: [Calculated Value]\n",
    "Precision: [Calculated Value]\n",
    "Recall: [Calculated Value]\n",
    "F1 Score: [Calculated Value]\n",
    "Gaussian Naive Bayes:\n",
    "\n",
    "Accuracy: [Calculated Value]\n",
    "Precision: [Calculated Value]\n",
    "Recall: [Calculated Value]\n",
    "F1 Score: [Calculated Value]\n",
    "Analysis:\n",
    "\n",
    "Based on the obtained results, the best-performing variant of Naive Bayes can be determined by comparing the mean values of the performance metrics across all classifiers.\n",
    "We can also analyze the results to understand the strengths and weaknesses of each variant of Naive Bayes in the context of the dataset and the task at hand.\n",
    "The choice of the best-performing variant may depend on various factors such as the distribution of features, the nature of the dataset, and the specific requirements of the classification task.\n",
    "Limitations:\n",
    "\n",
    "While Naive Bayes classifiers are simple and efficient, they make strong independence assumptions between features, which may not hold true in real-world datasets.\n",
    "Naive Bayes classifiers may perform poorly when the features are highly correlated or when the feature space is high-dimensional.\n",
    "Another limitation of Naive Bayes is its sensitivity to imbalanced datasets, where the class distribution is skewed, leading to biased predictions.\n",
    "Overall, the choice of the best-performing variant of Naive Bayes depends on the specific characteristics of the dataset and the classification task. It is essential to consider the strengths and limitations of each variant when selecting the appropriate classifier for a given problem. Additionally, further experimentation and analysis may be required to fine-tune the classifier's performance and address any observed limitations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27bdea-f30b-4312-9cb0-3104a878d5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
