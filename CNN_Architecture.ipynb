{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2766b5b3-58f9-492b-80b5-b69dc7043082",
   "metadata": {},
   "source": [
    "### Describe the purpose and benefits of pooling in CNN.\n",
    "### Explain the difference between min pooling and max pooling.\n",
    "### Discuss the concept of padding in CNN and its significance.\n",
    "### Compare and contrast zero-padding and valid-padding in terms of their effects on the output feature map size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74703e90-69a8-4309-9a07-0554884a4160",
   "metadata": {},
   "source": [
    "# CNN Concepts\n",
    "\n",
    "## 1. Describe the Purpose and Benefits of Pooling in CNN\n",
    "\n",
    "**Purpose of Pooling in CNN:**\n",
    "Pooling operations in CNNs aim to reduce the spatial dimensions (width and height) of the input feature maps. This process is also known as subsampling or downsampling.\n",
    "\n",
    "**Benefits of Pooling:**\n",
    "1. **Dimensionality Reduction**: Reduces the size of the feature maps, leading to fewer parameters and less computation, which helps in speeding up the training and inference processes.\n",
    "2. **Prevention of Overfitting**: By reducing the number of parameters, pooling helps to mitigate overfitting, especially in deeper networks.\n",
    "3. **Translation Invariance**: Makes the detection of features more robust to translations of the input, meaning small movements in the input do not significantly affect the pooled feature.\n",
    "4. **Feature Extraction**: Focuses on the most significant features, making it easier for the network to learn and generalize important patterns.\n",
    "\n",
    "## 2. Explain the Difference Between Min Pooling and Max Pooling\n",
    "\n",
    "**Max Pooling:**\n",
    "- **Mechanism**: In each patch of the feature map, max pooling selects the maximum value.\n",
    "- **Purpose**: Captures the most prominent feature in each patch, highlighting the strongest activation.\n",
    "- **Effect**: Helps retain the most significant information, enhancing the features that are most important for the task.\n",
    "\n",
    "**Min Pooling:**\n",
    "- **Mechanism**: In each patch of the feature map, min pooling selects the minimum value.\n",
    "- **Purpose**: Could be used to highlight regions of low activation, though it is less common in practice.\n",
    "- **Effect**: Typically not as effective for most tasks because it emphasizes the least significant information.\n",
    "\n",
    "**Key Difference:**\n",
    "- Max pooling emphasizes the strongest activations in the feature map, making it useful for highlighting the most important features, whereas min pooling emphasizes the weakest activations, which is generally less useful for the feature extraction process in CNNs.\n",
    "\n",
    "## 3. Discuss the Concept of Padding in CNN and Its Significance\n",
    "\n",
    "**Padding** is the process of adding extra pixels around the border of an input feature map. \n",
    "\n",
    "**Significance of Padding:**\n",
    "1. **Control Output Size**: Padding allows control over the spatial dimensions of the output feature map. Without padding, the size of the feature maps would decrease after each convolution operation.\n",
    "2. **Preserve Spatial Dimensions**: Padding helps to maintain the spatial dimensions of the input feature map, which can be important for certain applications.\n",
    "3. **Inclusion of Border Information**: Ensures that the convolutional filters can consider the border pixels of the input image, which might otherwise be ignored.\n",
    "\n",
    "## 4. Compare and Contrast Zero-Padding and Valid-Padding in Terms of Their Effects on the Output Feature Map Size\n",
    "\n",
    "**Zero-Padding (Same Padding):**\n",
    "- **Definition**: Adds zero-value pixels around the border of the input feature map.\n",
    "- **Effect on Output Size**: Maintains the same spatial dimensions as the input. For example, if the input is 28x28, the output after convolution with padding will also be 28x28.\n",
    "- **Use Case**: Useful when we want the output size to be the same as the input size, allowing deeper networks without reducing spatial dimensions.\n",
    "\n",
    "**Valid-Padding:**\n",
    "- **Definition**: No padding is applied, only valid input pixels are used.\n",
    "- **Effect on Output Size**: Reduces the spatial dimensions of the output. For example, if the input is 28x28 and a 3x3 filter is used, the output will be 26x26.\n",
    "- **Use Case**: Useful when we want to reduce the size of the feature map progressively, often used in networks where reducing dimensionality is desired.\n",
    "\n",
    "**Comparison:**\n",
    "- **Zero-Padding** maintains the input size, making it suitable for tasks where the spatial resolution needs to be preserved.\n",
    "- **Valid-Padding** reduces the output size, making it useful for tasks where spatial dimensionality needs to be reduced systematically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef59a2-7c61-4857-a22b-046c8ae31489",
   "metadata": {},
   "source": [
    "## TOPIC: Exploring LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1cd96-f8bd-4d6f-9f23-e530180e6200",
   "metadata": {},
   "source": [
    "# LeNet-5 Overview and Implementation\n",
    "\n",
    "## 1. Provide a Brief Overview of LeNet-5 Architecture\n",
    "\n",
    "LeNet-5 is a pioneering Convolutional Neural Network (CNN) architecture proposed by Yann LeCun and his colleagues in 1998. It was designed for handwritten digit recognition and played a key role in advancing the field of deep learning. The architecture consists of several layers, including convolutional layers, pooling layers, and fully connected layers, which together perform feature extraction and classification.\n",
    "\n",
    "## 2. Describe the Key Components of LeNet-5 and Their Respective Purposes\n",
    "\n",
    "**Key Components of LeNet-5:**\n",
    "\n",
    "1. **Input Layer**:\n",
    "   - **Size**: 32x32 pixels (typically grayscale images).\n",
    "   - **Purpose**: Accepts the input image for the network.\n",
    "\n",
    "2. **C1 - First Convolutional Layer**:\n",
    "   - **Filters**: 6 filters of size 5x5.\n",
    "   - **Output Size**: 28x28x6.\n",
    "   - **Purpose**: Extracts basic features such as edges and textures.\n",
    "\n",
    "3. **S2 - First Subsampling (Pooling) Layer**:\n",
    "   - **Type**: Average pooling.\n",
    "   - **Output Size**: 14x14x6.\n",
    "   - **Purpose**: Reduces spatial dimensions, retaining important information and reducing computational complexity.\n",
    "\n",
    "4. **C3 - Second Convolutional Layer**:\n",
    "   - **Filters**: 16 filters of size 5x5.\n",
    "   - **Output Size**: 10x10x16.\n",
    "   - **Purpose**: Extracts more complex features by combining lower-level features.\n",
    "\n",
    "5. **S4 - Second Subsampling (Pooling) Layer**:\n",
    "   - **Type**: Average pooling.\n",
    "   - **Output Size**: 5x5x16.\n",
    "   - **Purpose**: Further reduces spatial dimensions and computational complexity.\n",
    "\n",
    "6. **C5 - Third Convolutional Layer**:\n",
    "   - **Filters**: 120 filters of size 5x5.\n",
    "   - **Output Size**: 1x1x120.\n",
    "   - **Purpose**: Converts the feature maps into a vector of 120 features.\n",
    "\n",
    "7. **F6 - Fully Connected Layer**:\n",
    "   - **Units**: 84 neurons.\n",
    "   - **Purpose**: Acts as a traditional neural network layer, processing the extracted features for classification.\n",
    "\n",
    "8. **Output Layer**:\n",
    "   - **Units**: 10 neurons (for digit classification 0-9).\n",
    "   - **Activation**: Softmax.\n",
    "   - **Purpose**: Outputs the probability distribution over 10 classes.\n",
    "\n",
    "## 3. Discuss the Advantages and Limitations of LeNet-5 in the Context of Image Classification Tasks\n",
    "\n",
    "**Advantages:**\n",
    "1. **Pioneering Architecture**: One of the first CNNs that demonstrated the effectiveness of deep learning in image classification.\n",
    "2. **Simplicity**: The architecture is relatively simple and easy to understand, making it suitable for educational purposes.\n",
    "3. **Efficiency**: LeNet-5 is computationally efficient, requiring fewer resources compared to more modern architectures.\n",
    "\n",
    "**Limitations:**\n",
    "1. **Scalability**: Not suitable for high-resolution images and more complex tasks due to its shallow depth and small filter size.\n",
    "2. **Performance**: Outperformed by more modern architectures such as AlexNet, VGG, and ResNet, which have deeper layers and more complex structures.\n",
    "3. **Flexibility**: Limited flexibility in handling different types of input data and tasks beyond digit recognition.\n",
    "\n",
    "## 4. Implement LeNet-5 Using a Deep Learning Framework of Your Choice (e.g., TensorFlow, PyTorch) and Train it on a Publicly Available Dataset (e.g., MNIST). Evaluate its Performance and Provide Insights.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define LeNet-5 architecture\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.conv1(x))\n",
    "        x = nn.functional.avg_pool2d(x, 2)\n",
    "        x = torch.tanh(self.conv2(x))\n",
    "        x = nn.functional.avg_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), # Resize to 32x32\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Instantiate model, define loss function and optimizer\n",
    "model = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test dataset: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a56c5-651b-4508-8ce1-4c021ec3b281",
   "metadata": {},
   "source": [
    "# AlexNet Overview and Implementation\n",
    "\n",
    "## 1. Present an Overview of the AlexNet Architecture\n",
    "\n",
    "AlexNet is a deep convolutional neural network architecture that won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012, significantly outperforming the previous state-of-the-art. It was designed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. AlexNet consists of eight layers: five convolutional layers followed by three fully connected layers, and employs ReLU activation functions, dropout regularization, and data augmentation.\n",
    "\n",
    "## 2. Explain the Architectural Innovations Introduced in AlexNet that Contributed to its Breakthrough Performance\n",
    "\n",
    "**Architectural Innovations:**\n",
    "\n",
    "1. **ReLU Activation Function**:\n",
    "   - **Innovation**: ReLU (Rectified Linear Unit) activation function was used instead of the traditional tanh or sigmoid functions.\n",
    "   - **Impact**: Improved training time significantly due to its non-saturating property, leading to faster convergence.\n",
    "\n",
    "2. **Dropout**:\n",
    "   - **Innovation**: Dropout regularization was applied in the fully connected layers.\n",
    "   - **Impact**: Helped in reducing overfitting by randomly dropping units during training.\n",
    "\n",
    "3. **Data Augmentation**:\n",
    "   - **Innovation**: Employed extensive data augmentation techniques like image translations, horizontal reflections, and patch extractions.\n",
    "   - **Impact**: Increased the effective size of the training dataset, improving the model's generalization ability.\n",
    "\n",
    "4. **GPU Utilization**:\n",
    "   - **Innovation**: Trained on two NVIDIA GPUs, allowing for parallel processing of the network.\n",
    "   - **Impact**: Enabled the training of a much larger and deeper network compared to previous models.\n",
    "\n",
    "5. **Local Response Normalization**:\n",
    "   - **Innovation**: Introduced Local Response Normalization (LRN) after ReLU activations.\n",
    "   - **Impact**: Helped in inducing lateral inhibition, mimicking the behavior of real neurons, and improved generalization.\n",
    "\n",
    "## 3. Discuss the Role of Convolutional Layers, Pooling Layers, and Fully Connected Layers in AlexNet\n",
    "\n",
    "**Convolutional Layers**:\n",
    "- **Role**: Responsible for feature extraction by applying filters to the input image and capturing local patterns such as edges, textures, and more complex structures in deeper layers.\n",
    "- **Impact**: These layers learn spatial hierarchies of features automatically from the input images.\n",
    "\n",
    "**Pooling Layers**:\n",
    "- **Role**: Perform downsampling operations (usually max pooling) to reduce the spatial dimensions of the feature maps.\n",
    "- **Impact**: Help in reducing the computational complexity and the number of parameters, and provide translational invariance.\n",
    "\n",
    "**Fully Connected Layers**:\n",
    "- **Role**: Act as a traditional neural network layer that connects every neuron in one layer to every neuron in the next layer.\n",
    "- **Impact**: These layers integrate the features extracted by the convolutional layers to perform the final classification.\n",
    "\n",
    "## 4. Implement AlexNet Using a Deep Learning Framework of Your Choice and Evaluate its Performance on a Dataset of Your Choice\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define AlexNet architecture\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Instantiate model, define loss function and optimizer\n",
    "model = AlexNet(num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test dataset: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbfa1557-530d-4698-b2bd-d792b6f30c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def alexnet(img_shape=(224, 224, 3), num_classes=1000):\n",
    "  \"\"\"\n",
    "  Defines the AlexNet architecture.\n",
    "\n",
    "  Args:\n",
    "      img_shape: Input image shape (height, width, channels).\n",
    "      num_classes: Number of output classes.\n",
    "\n",
    "  Returns:\n",
    "      A compiled Keras model.\n",
    "  \"\"\"\n",
    "\n",
    "  # Input layer\n",
    "  inputs = layers.Input(shape=img_shape)\n",
    "\n",
    "  # Convolutional layers (Group 1)\n",
    "  x = layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation='relu')(inputs)\n",
    "  x = layers.MaxPooling2D(pool_size=(3, 3), strides=2)(x)\n",
    "  x = layers.Lambda(tf.nn.local_response_normalization)(x)  # Local Response Normalization (LRN)\n",
    "\n",
    "  # Convolutional layers (Group 2)\n",
    "  x = layers.Conv2D(filters=256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "  x = layers.MaxPooling2D(pool_size=(3, 3), strides=2)(x)\n",
    "  x = layers.Lambda(tf.nn.local_response_normalization)(x)\n",
    "\n",
    "  # Convolutional layers (Group 3)\n",
    "  x = layers.Conv2D(filters=384, kernel_size=3, padding='same', activation='relu')(x)\n",
    "  x = layers.Conv2D(filters=384, kernel_size=3, padding='same', activation='relu')(x)\n",
    "  x = layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "  x = layers.MaxPooling2D(pool_size=(3, 3), strides=2)(x)\n",
    "\n",
    "  # Fully-connected layers\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(4096, activation='relu')(x)\n",
    "  x = layers.Dropout(0.5)(x)  # Dropout for regularization\n",
    "  x = layers.Dense(4096, activation='relu')(x)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "\n",
    "  # Output layer\n",
    "  outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  # Compile model\n",
    "  model = Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1344bf-94fb-447e-83cc-23f32b04e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
